{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d9881f",
   "metadata": {},
   "source": [
    "# Fake News Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199aaa4",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5326f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafc2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3f66dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "### Printing the stopwords.\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35afa5",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c08a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake-news-prediction-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7418b76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8dc240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8992e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520e18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0dd73",
   "metadata": {},
   "source": [
    "### Replacing the null values with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc91d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b53aa2",
   "metadata": {},
   "source": [
    "### Merging the author name and news title \n",
    "Here we can also take 'text' feature but the processing will take very much larger time as text have larger paragraphs. That's why we take and merge author name and news title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70018963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['author']+ ' ' +df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9fd6382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
       "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
       "2        Consortiumnews.com Why the Truth Might Get You...\n",
       "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
       "4        Howard Portnoy Iranian woman jailed for fictio...\n",
       "                               ...                        \n",
       "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
       "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
       "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
       "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
       "20799              David Swanson What Keeps the F-35 Alive\n",
       "Name: content, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540c9a6",
   "metadata": {},
   "source": [
    "Stemming: \n",
    "Stemming is the process of reducing a word to its Root word.\n",
    "\n",
    "example:\n",
    "actor, actress, acting --> act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc4aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e591055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ', content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24023c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(stemming) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8362afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        darrel lucu hous dem aid even see comey letter...\n",
      "1        daniel j flynn flynn hillari clinton big woman...\n",
      "2                   consortiumnew com truth might get fire\n",
      "3        jessica purkiss civilian kill singl us airstri...\n",
      "4        howard portnoy iranian woman jail fiction unpu...\n",
      "                               ...                        \n",
      "20795    jerom hudson rapper trump poster child white s...\n",
      "20796    benjamin hoffman n f l playoff schedul matchup...\n",
      "20797    michael j de la merc rachel abram maci said re...\n",
      "20798    alex ansari nato russia hold parallel exercis ...\n",
      "20799                            david swanson keep f aliv\n",
      "Name: content, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed25ac",
   "metadata": {},
   "source": [
    "### Separating the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf6dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca1114",
   "metadata": {},
   "source": [
    "### Converting the textual data to the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4a536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ae0ff",
   "metadata": {},
   "source": [
    "### Splitting the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "455149ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee38cd",
   "metadata": {},
   "source": [
    "### Fitting the different model into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71d8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier, XGBRFClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03a45f",
   "metadata": {},
   "source": [
    "#### Defining a function fit_model for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d60e3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    print('The predicted values:\\n ', model.predict(X_test))\n",
    "    print('\\nThe accuracy score: ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2693c",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a228972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.9774038461538461\n"
     ]
    }
   ],
   "source": [
    "fit_model(LogisticRegression(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4859dd",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b57978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.9901442307692307\n"
     ]
    }
   ],
   "source": [
    "fit_model(RandomForestClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd755aed",
   "metadata": {},
   "source": [
    "### 3. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56f79ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.9901442307692307\n"
     ]
    }
   ],
   "source": [
    "fit_model(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678abb2",
   "metadata": {},
   "source": [
    "### 4. Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b66b66b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.9920673076923077\n"
     ]
    }
   ],
   "source": [
    "fit_model(SVC(kernel='linear'), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c13441",
   "metadata": {},
   "source": [
    "### 5. XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b3792e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.9867788461538461\n"
     ]
    }
   ],
   "source": [
    "fit_model(XGBClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970421b2",
   "metadata": {},
   "source": [
    "### 6. XGBRF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d070a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The predicted values:\n",
      "  [1 1 1 ... 1 1 1]\n",
      "\n",
      "The accuracy score:  0.948076923076923\n"
     ]
    }
   ],
   "source": [
    "fit_model(XGBRFClassifier(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84d42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
